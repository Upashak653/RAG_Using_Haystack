{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/deepset-ai/haystack.git@main\n",
      "  Cloning https://github.com/deepset-ai/haystack.git (to revision main) to /tmp/pip-req-build-sw6lay9c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/deepset-ai/haystack.git /tmp/pip-req-build-sw6lay9c\n",
      "  Resolved https://github.com/deepset-ai/haystack.git to commit 1d96e6e4af385b2ae00fd07c085abc8d6799e685\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: docstring-parser in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (0.17.0)\n",
      "Collecting filetype (from haystack-ai==2.17.0rc0)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting haystack-experimental (from haystack-ai==2.17.0rc0)\n",
      "  Downloading haystack_experimental-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (4.25.0)\n",
      "Collecting lazy-imports (from haystack-ai==2.17.0rc0)\n",
      "  Downloading lazy_imports-1.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (10.7.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (3.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (2.0.2)\n",
      "Requirement already satisfied: openai>=1.56.1 in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (1.97.1)\n",
      "Collecting posthog!=3.12.0 (from haystack-ai==2.17.0rc0)\n",
      "  Downloading posthog-6.3.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (2.11.7)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (8.5.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from haystack-ai==2.17.0rc0) (4.14.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai==2.17.0rc0) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai==2.17.0rc0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai==2.17.0rc0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai==2.17.0rc0) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.56.1->haystack-ai==2.17.0rc0) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog!=3.12.0->haystack-ai==2.17.0rc0) (1.17.0)\n",
      "Collecting backoff>=1.10.0 (from posthog!=3.12.0->haystack-ai==2.17.0rc0)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->haystack-ai==2.17.0rc0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->haystack-ai==2.17.0rc0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->haystack-ai==2.17.0rc0) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->haystack-ai==2.17.0rc0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->haystack-ai==2.17.0rc0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->haystack-ai==2.17.0rc0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->haystack-ai==2.17.0rc0) (2025.7.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->haystack-ai==2.17.0rc0) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai==2.17.0rc0) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai==2.17.0rc0) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai==2.17.0rc0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->haystack-ai==2.17.0rc0) (0.26.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai==2.17.0rc0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai==2.17.0rc0) (0.16.0)\n",
      "Downloading posthog-6.3.1-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading haystack_experimental-0.12.0-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lazy_imports-1.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: haystack-ai\n",
      "  Building wheel for haystack-ai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for haystack-ai: filename=haystack_ai-2.17.0rc0-py3-none-any.whl size=575587 sha256=9f71bde47d1af70ddaefea56520f4edc50c0f025a047a6603896d925e1e2851b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qlee0bi8/wheels/b1/48/49/19ff23db8ee37ab13155d169607bf99ee3d13fc90877af4437\n",
      "Successfully built haystack-ai\n",
      "Installing collected packages: filetype, lazy-imports, backoff, posthog, haystack-experimental, haystack-ai\n",
      "Successfully installed backoff-2.2.1 filetype-1.2.0 haystack-ai-2.17.0rc0 haystack-experimental-0.12.0 lazy-imports-1.0.0 posthog-6.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/deepset-ai/haystack.git@main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.dataclasses import Document\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20abb91aee04e598e69d0ccd7d7c6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/46.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de25da17cb246fd85c62b5e7640bb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-4077bd623d55100a.parquet:   0%|          | 0.00/119k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136a32b154db4fdeba4e27811f962502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/151 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "docs = [Document(content = doc[\"content\"],meta=doc[\"meta\"]) for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef49c3cb3cb74370abdb0038df7a9a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2728c10a5014b3b99cf71f5666803be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057e41e74a254026bbd87723789ee0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c444863ba949018431e4734bfd9f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024bfcdb10624e718988c90ba3696dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45e34efcab349cc9ae13df22717ddf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa2a5681de24faba29552ba4984a451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1672207c4f4fb5bc9443788e403ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2664fa7214dd405eaca6e5ddbe329d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d922ab829bf4e8cbdc588ab7d01df4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f5377208d44cafab144e413e04d37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embedder.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d0af0e0d7e4f96be29f9f580313eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "retriever = InMemoryEmbeddingRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:haystack.components.builders.chat_prompt_builder:ChatPromptBuilder has 2 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "\n",
    "template = [\n",
    "    ChatMessage.from_user(\n",
    "        \"\"\"\n",
    "        Given the following information , answer the question.\n",
    "\n",
    "        Context:\n",
    "        {% for document in documents %}\n",
    "          {{document.content}}\n",
    "        {%endfor%}\n",
    "\n",
    "        Question : {{question}}\n",
    "        Answer :\n",
    "        \"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt_builder=ChatPromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    from google.colab import auth\n",
    "    os.environ[\"OPENAI_API_KEY\"] = input(\"🔐 Paste your OpenAI API key here : \").strip()\n",
    "\n",
    "chat_generator = OpenAIChatGenerator(model=\"gpt-4o-mini\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "basic_rag_pipeline = Pipeline()\n",
    "\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", chat_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7c8195e68d10>\n",
       "🚅 Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: OpenAIChatGenerator\n",
       "🛤️ Connections\n",
       "  - text_embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.messages (List[ChatMessage])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66b6b6e66994f37924102d6f812ec72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Colossus of Rhodes was a massive statue of the Greek sun-god Helios, standing approximately 70 cubits, or about 33 meters (108 feet) tall. Although the exact appearance of the statue is not definitively known, ancient accounts provide a general description. It was constructed with iron tie bars and brass plates to form its skin. The statue is believed to have had curly hair with evenly spaced spikes, resembling bronze or silver flames radiating from the head, similar to images found on contemporary Rhodian coins.\n",
      "\n",
      "The interior of the statue was filled with stone blocks, and it stood on a 15-meter-high (49-foot) white marble pedestal near the entrance to Rhodes harbor. The statue was an impressive sight, representing freedom and independence, and was meant to celebrate Rhodes' successful defense against an attack by Demetrius Poliorcetes. Its posture is often imagined as heroic and dynamic, possibly suggesting a pose similar to that of Helios shielding his eyes from the sun. The overall impression of the statue conveyed power, significance, and reverence for the gods.\n"
     ]
    }
   ],
   "source": [
    "question = \"What does Rhodes Statue look like?\"\n",
    "\n",
    "response = basic_rag_pipeline.run({\"text_embedder\":{\"text\":question},\"prompt_builder\":{\"question\":question}})\n",
    "print(response[\"llm\"][\"replies\"][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
